# Server Testing Guide

Server ì½”ë“œë¥¼ Clientì—ì„œ ìƒì„±í•œ vision embeddingìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ í…ŒìŠ¤íŠ¸ ì ˆì°¨

### **Phase 1: Clientì—ì„œ Embedding ìƒì„±**

```bash
cd client

# 1. ì´ë¯¸ì§€ embedding ìƒì„±
python save_test_embeddings.py image <path_to_image> ../test_data

# 2. ë¹„ë””ì˜¤ embedding ìƒì„±
python save_test_embeddings.py video <path_to_video> ../test_data

# ì˜ˆì‹œ:
python save_test_embeddings.py image ../cookbooks/assets/omni_recognition/image_example.jpg
python save_test_embeddings.py video ../cookbooks/assets/omni_recognition/video_example.mp4
```

**ìƒì„±ë˜ëŠ” íŒŒì¼:**
- `{media_type}_{filename}_tensors.pt` - PyTorch í…ì„œ (input_ids, vision_embeddings, etc.)
- `{media_type}_{filename}_metadata.json` - ë©”íƒ€ë°ì´í„°
- `{media_type}_{filename}_info.txt` - ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ìš”ì•½

---

### **Phase 2: Serverì—ì„œ Embeddingìœ¼ë¡œ í…ŒìŠ¤íŠ¸**

```bash
cd server

# 1. ì˜ì¡´ì„± ì„¤ì¹˜ (ì²˜ìŒ í•œ ë²ˆë§Œ)
pip install -r requirements.txt

# 2. ì €ì¥ëœ embeddingìœ¼ë¡œ í…ŒìŠ¤íŠ¸
python test_server_with_embeddings.py ../test_data/image_example_tensors.pt
python test_server_with_embeddings.py ../test_data/video_example_tensors.pt
```

**í…ŒìŠ¤íŠ¸ ë‚´ìš©:**
- âœ… Embedding ë¡œë“œ
- âœ… Server LLM ì´ˆê¸°í™”
- âœ… Non-streaming ìƒì„±
- âœ… Streaming ìƒì„±

---

### **ìë™í™” ìŠ¤í¬ë¦½íŠ¸ (ì˜µì…˜)**

ì „ì²´ í…ŒìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì‹¤í–‰:

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ
./run_tests.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ”:
1. Clientì—ì„œ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ embedding ìƒì„±
2. Serverì—ì„œ ê° embedding í…ŒìŠ¤íŠ¸
3. ê²°ê³¼ ìš”ì•½ ì¶œë ¥

---

## ğŸ“ ì €ì¥ëœ ë°ì´í„° êµ¬ì¡°

```
test_data/
â”œâ”€â”€ image_example_tensors.pt       # ì´ë¯¸ì§€ í…ì„œ
â”œâ”€â”€ image_example_metadata.json    # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
â”œâ”€â”€ image_example_info.txt         # ì´ë¯¸ì§€ ì •ë³´
â”œâ”€â”€ video_example_tensors.pt       # ë¹„ë””ì˜¤ í…ì„œ
â”œâ”€â”€ video_example_metadata.json    # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°
â””â”€â”€ video_example_info.txt         # ë¹„ë””ì˜¤ ì •ë³´
```

### **í…ì„œ íŒŒì¼ ë‚´ìš©**

```python
data = torch.load('image_example_tensors.pt')
# Keys:
# - 'input_ids': torch.Tensor, shape [1, seq_len]
# - 'attention_mask': torch.Tensor, shape [1, seq_len]
# - 'vision_embeddings': torch.Tensor, shape [num_patches, hidden_dim]
# - 'vision_token_positions': List[int]
```

---

## ğŸ§ª ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

### **Pythonì—ì„œ ì§ì ‘ ë¡œë“œ**

```python
import torch

# 1. ë°ì´í„° ë¡œë“œ
data = torch.load('test_data/image_example_tensors.pt')

# 2. Server ì´ˆê¸°í™”
from llm_inference import ServerLLMInference
llm = ServerLLMInference(model_name="Qwen/Qwen3-VL-2B-Instruct")

# 3. ìƒì„±
response = llm.generate(
    input_ids=data['input_ids'],
    vision_embeddings=data['vision_embeddings'],
    vision_token_positions=data['vision_token_positions'],
    attention_mask=data['attention_mask'],
    max_new_tokens=128
)

print(response)
```

---

## ğŸ” ë””ë²„ê¹…

### **ë¬¸ì œ: Embedding íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ**

```bash
# Client í™˜ê²½ í™•ì¸
cd client
python -c "import torch; from preprocessor import ClientPreprocessor; print('OK')"

# GPU ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### **ë¬¸ì œ: Server í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨**

```bash
# Server í™˜ê²½ í™•ì¸
cd server
python -c "from llm_inference import ServerLLMInference; print('OK')"

# Embedding shape í™•ì¸
python -c "import torch; d = torch.load('../test_data/image_example_tensors.pt'); print(d['vision_embeddings'].shape)"
```

---

## ğŸ“Š ì˜ˆìƒ ì¶œë ¥

### **save_test_embeddings.py**

```
================================================================================
ğŸ’¾ Saving IMAGE Embedding Data for Server Testing
================================================================================

[Step 1/5] Initializing preprocessor and encoder...
ğŸ“¦ Loading processor for Qwen/Qwen3-VL-2B-Instruct...
âœ… Processor loaded! Patch size: 16
ğŸš€ Loading Vision Encoder from Qwen/Qwen3-VL-2B-Instruct...
   Target device: cuda:0
   âœ… Vision Encoder loaded!

[Step 2/5] Creating messages for image...

[Step 3/5] Preprocessing...
   âœ… Preprocessing complete:
      - input_ids: torch.Size([1, 45])
      - attention_mask: torch.Size([1, 45])

[Step 4/5] Encoding vision features...
ğŸ¨ Encoding vision features...
   Input pixel_values shape: torch.Size([1225, 1176])
   Grid THW shape: torch.Size([1, 3]), values: tensor([[1, 35, 35]])
âœ… Vision encoding complete!
   Output shape: torch.Size([1225, 2048])
   âœ… Vision embeddings: torch.Size([1225, 2048])
      - Vision token positions: [9]

[Step 5/5] Saving data...
   âœ… Saved: ../test_data/image_example_tensors.pt
   âœ… Saved: ../test_data/image_example_metadata.json
   âœ… Saved: ../test_data/image_example_info.txt

ğŸ‰ All data saved successfully!
```

### **test_server_with_embeddings.py**

```
================================================================================
ğŸ§ª Testing Server with Pre-computed Embeddings
================================================================================

[Step 1/4] Loading embeddings from ../test_data/image_example_tensors.pt...
   âœ… Data loaded:
      - input_ids: torch.Size([1, 45])
      - vision_embeddings: torch.Size([1225, 2048])
      - vision_token_positions: [9]

[Step 2/4] Initializing Server LLM...
ğŸš€ Starting Qwen3-VL Inference Server
âœ… Model loaded on cuda:0
   âœ… Server LLM loaded!

[Step 3/4] Generating response (non-streaming)...
ğŸ”¥ Starting generation...
ğŸš€ Running LLM generation...
âœ… Generation complete: 245 chars

================================================================================
ğŸ“ Generated Response:
================================================================================
ì´ ì´ë¯¸ì§€ëŠ” í•´ë³€ì˜ ì¼ëª° ì¥ë©´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í•˜ëŠ˜ì€ ì£¼í™©ìƒ‰ê³¼ ë¶„í™ìƒ‰ìœ¼ë¡œ ë¬¼ë“¤ì–´ ìˆìœ¼ë©°...
================================================================================

[Step 4/4] Testing streaming generation...
================================================================================
ğŸ“ Streaming Response:
================================================================================
ì´ ì´ë¯¸ì§€ëŠ” í•´ë³€ì˜ ì¼ëª° ì¥ë©´ì„ ë³´ì—¬ì¤ë‹ˆë‹¤...
================================================================================

âœ… Streaming generation complete!

ğŸ“Š Test Summary
âœ… All server tests passed!
```

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

Embedding í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´:

1. **FastAPI ì„œë²„ ì‹œì‘**
   ```bash
   cd server
   python server_api.py
   ```

2. **Gradio Client ì‹œì‘**
   ```bash
   cd client
   python gradio_app.py
   ```

3. **End-to-End í…ŒìŠ¤íŠ¸**
   - ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:7860` ì ‘ì†
   - ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì—…ë¡œë“œ
   - í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥
   - ìƒì„± ê²°ê³¼ í™•ì¸
